{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e1e325a-5bf8-4557-acac-35d5e64d6022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Word Count\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>word</th><th>count</th></tr></thead><tbody><tr><td>about</td><td>1</td></tr><tr><td>without</td><td>2</td></tr><tr><td>reason</td><td>1</td></tr><tr><td>static</td><td>1</td></tr><tr><td>a</td><td>8</td></tr><tr><td>computation</td><td>3</td></tr><tr><td>event-time</td><td>1</td></tr><tr><td>use</td><td>1</td></tr><tr><td>logs</td><td>1</td></tr><tr><td>it</td><td>1</td></tr><tr><td>spark</td><td>4</td></tr><tr><td>stream-to-batch</td><td>1</td></tr><tr><td>continues</td><td>1</td></tr><tr><td>fast,</td><td>1</td></tr><tr><td>arrive</td><td>1</td></tr><tr><td>r</td><td>1</td></tr><tr><td>can</td><td>3</td></tr><tr><td>final</td><td>1</td></tr><tr><td>guarantees</td><td>3</td></tr><tr><td>to</td><td>6</td></tr><tr><td>in</td><td>4</td></tr><tr><td>would</td><td>1</td></tr><tr><td>will</td><td>2</td></tr><tr><td>system</td><td>1</td></tr><tr><td>ensures</td><td>1</td></tr><tr><td>engine</td><td>4</td></tr><tr><td>python</td><td>1</td></tr><tr><td>or</td><td>1</td></tr><tr><td>checkpointing</td><td>1</td></tr><tr><td>take</td><td>1</td></tr><tr><td>scalable</td><td>1</td></tr><tr><td>joins,</td><td>1</td></tr><tr><td>finally,</td><td>1</td></tr><tr><td>exactly-once</td><td>3</td></tr><tr><td>stream</td><td>2</td></tr><tr><td>dataset/dataframe</td><td>2</td></tr><tr><td>the</td><td>15</td></tr><tr><td>of</td><td>3</td></tr><tr><td>built</td><td>1</td></tr><tr><td>end-to-end</td><td>4</td></tr><tr><td>write-ahead</td><td>1</td></tr><tr><td>executed</td><td>1</td></tr><tr><td>java,</td><td>1</td></tr><tr><td>structured</td><td>4</td></tr><tr><td>is</td><td>2</td></tr><tr><td>provides</td><td>1</td></tr><tr><td>and</td><td>7</td></tr><tr><td>fault-tolerance</td><td>2</td></tr><tr><td>result</td><td>1</td></tr><tr><td>way</td><td>1</td></tr><tr><td>fault-tolerant,</td><td>1</td></tr><tr><td>running</td><td>1</td></tr><tr><td>incrementally</td><td>1</td></tr><tr><td>scala,</td><td>1</td></tr><tr><td>user</td><td>1</td></tr><tr><td>care</td><td>1</td></tr><tr><td>batch</td><td>2</td></tr><tr><td>as</td><td>6</td></tr><tr><td>your</td><td>3</td></tr><tr><td>streaming</td><td>9</td></tr><tr><td>fault-tolerant</td><td>1</td></tr><tr><td>optimized</td><td>1</td></tr><tr><td>processing</td><td>6</td></tr><tr><td>windows,</td><td>1</td></tr><tr><td>same</td><td>2</td></tr><tr><td>scalable,</td><td>1</td></tr><tr><td>through</td><td>2</td></tr><tr><td>you</td><td>5</td></tr><tr><td>express</td><td>3</td></tr><tr><td>on</td><td>4</td></tr><tr><td>api</td><td>1</td></tr><tr><td>aggregations,</td><td>1</td></tr><tr><td>short,</td><td>1</td></tr><tr><td>sql</td><td>3</td></tr><tr><td>having</td><td>1</td></tr><tr><td>continuously</td><td>1</td></tr><tr><td>data</td><td>3</td></tr><tr><td>updating</td><td>1</td></tr><tr><td>etc</td><td>1</td></tr><tr><td>engine,</td><td>1</td></tr><tr><td>by</td><td>1</td></tr><tr><td>we</td><td>3</td></tr><tr><td>millisecond</td><td>1</td></tr><tr><td>using</td><td>2</td></tr><tr><td>able</td><td>1</td></tr><tr><td>at-least-once</td><td>1</td></tr><tr><td>processes</td><td>1</td></tr><tr><td>introduced</td><td>1</td></tr><tr><td>low</td><td>2</td></tr><tr><td>are</td><td>3</td></tr><tr><td>changing</td><td>1</td></tr><tr><td>be</td><td>1</td></tr><tr><td>new</td><td>1</td></tr><tr><td>processing,</td><td>1</td></tr><tr><td>small</td><td>1</td></tr><tr><td>mode</td><td>2</td></tr><tr><td>called</td><td>1</td></tr><tr><td>requirements</td><td>1</td></tr><tr><td>choose</td><td>1</td></tr><tr><td>latencies</td><td>2</td></tr><tr><td>queries</td><td>1</td></tr><tr><td>which</td><td>2</td></tr><tr><td>operations</td><td>1</td></tr><tr><td>low-latency</td><td>1</td></tr><tr><td>jobs</td><td>1</td></tr><tr><td>processed</td><td>1</td></tr><tr><td>with</td><td>2</td></tr><tr><td>internally,</td><td>1</td></tr><tr><td>have</td><td>1</td></tr><tr><td>queries,</td><td>1</td></tr><tr><td>since</td><td>1</td></tr><tr><td>milliseconds</td><td>1</td></tr><tr><td>default,</td><td>1</td></tr><tr><td>series</td><td>1</td></tr><tr><td>micro-batch</td><td>2</td></tr><tr><td>continuous</td><td>2</td></tr><tr><td>however,</td><td>1</td></tr><tr><td>streams</td><td>1</td></tr><tr><td>thereby</td><td>1</td></tr><tr><td>based</td><td>1</td></tr><tr><td>achieving</td><td>1</td></tr><tr><td>achieve</td><td>1</td></tr><tr><td>application</td><td>1</td></tr><tr><td>model</td><td>2</td></tr><tr><td>guide,</td><td>1</td></tr><tr><td>then</td><td>1</td></tr><tr><td>simple</td><td>1</td></tr><tr><td>count</td><td>1</td></tr><tr><td>going</td><td>2</td></tr><tr><td>mostly</td><td>1</td></tr><tr><td>discuss</td><td>1</td></tr><tr><td>walk</td><td>1</td></tr><tr><td>first,</td><td>1</td></tr><tr><td>later</td><td>1</td></tr><tr><td>programming</td><td>1</td></tr><tr><td>word</td><td>1</td></tr><tr><td>default</td><td>1</td></tr><tr><td>concepts</td><td>1</td></tr><tr><td>model,</td><td>1</td></tr><tr><td>explain</td><td>1</td></tr><tr><td>start</td><td>1</td></tr><tr><td>query</td><td>1</td></tr><tr><td>example</td><td>1</td></tr><tr><td>letâ€™s</td><td>1</td></tr><tr><td>apis</td><td>1</td></tr><tr><td>this</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "about",
         1
        ],
        [
         "without",
         2
        ],
        [
         "reason",
         1
        ],
        [
         "static",
         1
        ],
        [
         "a",
         8
        ],
        [
         "computation",
         3
        ],
        [
         "event-time",
         1
        ],
        [
         "use",
         1
        ],
        [
         "logs",
         1
        ],
        [
         "it",
         1
        ],
        [
         "spark",
         4
        ],
        [
         "stream-to-batch",
         1
        ],
        [
         "continues",
         1
        ],
        [
         "fast,",
         1
        ],
        [
         "arrive",
         1
        ],
        [
         "r",
         1
        ],
        [
         "can",
         3
        ],
        [
         "final",
         1
        ],
        [
         "guarantees",
         3
        ],
        [
         "to",
         6
        ],
        [
         "in",
         4
        ],
        [
         "would",
         1
        ],
        [
         "will",
         2
        ],
        [
         "system",
         1
        ],
        [
         "ensures",
         1
        ],
        [
         "engine",
         4
        ],
        [
         "python",
         1
        ],
        [
         "or",
         1
        ],
        [
         "checkpointing",
         1
        ],
        [
         "take",
         1
        ],
        [
         "scalable",
         1
        ],
        [
         "joins,",
         1
        ],
        [
         "finally,",
         1
        ],
        [
         "exactly-once",
         3
        ],
        [
         "stream",
         2
        ],
        [
         "dataset/dataframe",
         2
        ],
        [
         "the",
         15
        ],
        [
         "of",
         3
        ],
        [
         "built",
         1
        ],
        [
         "end-to-end",
         4
        ],
        [
         "write-ahead",
         1
        ],
        [
         "executed",
         1
        ],
        [
         "java,",
         1
        ],
        [
         "structured",
         4
        ],
        [
         "is",
         2
        ],
        [
         "provides",
         1
        ],
        [
         "and",
         7
        ],
        [
         "fault-tolerance",
         2
        ],
        [
         "result",
         1
        ],
        [
         "way",
         1
        ],
        [
         "fault-tolerant,",
         1
        ],
        [
         "running",
         1
        ],
        [
         "incrementally",
         1
        ],
        [
         "scala,",
         1
        ],
        [
         "user",
         1
        ],
        [
         "care",
         1
        ],
        [
         "batch",
         2
        ],
        [
         "as",
         6
        ],
        [
         "your",
         3
        ],
        [
         "streaming",
         9
        ],
        [
         "fault-tolerant",
         1
        ],
        [
         "optimized",
         1
        ],
        [
         "processing",
         6
        ],
        [
         "windows,",
         1
        ],
        [
         "same",
         2
        ],
        [
         "scalable,",
         1
        ],
        [
         "through",
         2
        ],
        [
         "you",
         5
        ],
        [
         "express",
         3
        ],
        [
         "on",
         4
        ],
        [
         "api",
         1
        ],
        [
         "aggregations,",
         1
        ],
        [
         "short,",
         1
        ],
        [
         "sql",
         3
        ],
        [
         "having",
         1
        ],
        [
         "continuously",
         1
        ],
        [
         "data",
         3
        ],
        [
         "updating",
         1
        ],
        [
         "etc",
         1
        ],
        [
         "engine,",
         1
        ],
        [
         "by",
         1
        ],
        [
         "we",
         3
        ],
        [
         "millisecond",
         1
        ],
        [
         "using",
         2
        ],
        [
         "able",
         1
        ],
        [
         "at-least-once",
         1
        ],
        [
         "processes",
         1
        ],
        [
         "introduced",
         1
        ],
        [
         "low",
         2
        ],
        [
         "are",
         3
        ],
        [
         "changing",
         1
        ],
        [
         "be",
         1
        ],
        [
         "new",
         1
        ],
        [
         "processing,",
         1
        ],
        [
         "small",
         1
        ],
        [
         "mode",
         2
        ],
        [
         "called",
         1
        ],
        [
         "requirements",
         1
        ],
        [
         "choose",
         1
        ],
        [
         "latencies",
         2
        ],
        [
         "queries",
         1
        ],
        [
         "which",
         2
        ],
        [
         "operations",
         1
        ],
        [
         "low-latency",
         1
        ],
        [
         "jobs",
         1
        ],
        [
         "processed",
         1
        ],
        [
         "with",
         2
        ],
        [
         "internally,",
         1
        ],
        [
         "have",
         1
        ],
        [
         "queries,",
         1
        ],
        [
         "since",
         1
        ],
        [
         "milliseconds",
         1
        ],
        [
         "default,",
         1
        ],
        [
         "series",
         1
        ],
        [
         "micro-batch",
         2
        ],
        [
         "continuous",
         2
        ],
        [
         "however,",
         1
        ],
        [
         "streams",
         1
        ],
        [
         "thereby",
         1
        ],
        [
         "based",
         1
        ],
        [
         "achieving",
         1
        ],
        [
         "achieve",
         1
        ],
        [
         "application",
         1
        ],
        [
         "model",
         2
        ],
        [
         "guide,",
         1
        ],
        [
         "then",
         1
        ],
        [
         "simple",
         1
        ],
        [
         "count",
         1
        ],
        [
         "going",
         2
        ],
        [
         "mostly",
         1
        ],
        [
         "discuss",
         1
        ],
        [
         "walk",
         1
        ],
        [
         "first,",
         1
        ],
        [
         "later",
         1
        ],
        [
         "programming",
         1
        ],
        [
         "word",
         1
        ],
        [
         "default",
         1
        ],
        [
         "concepts",
         1
        ],
        [
         "model,",
         1
        ],
        [
         "explain",
         1
        ],
        [
         "start",
         1
        ],
        [
         "query",
         1
        ],
        [
         "example",
         1
        ],
        [
         "letâ€™s",
         1
        ],
        [
         "apis",
         1
        ],
        [
         "this",
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "word",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, split, trim, col, lower\n",
    "class batchWordCount:\n",
    "    def __init__(self):\n",
    "        self.base_data = \"/Volumes/spark-catalog/sandbox/sample_data/\"\n",
    "    \n",
    "    def getRawData(self):\n",
    "        lines = (spark.read.format(\"text\") \\\n",
    "                     .option(\"lineSep\", \".\") \\\n",
    "                     .load(f\"{self.base_data}/text_data_*.txt\"))\n",
    "        return lines.select(explode(split(col(\"value\"), \" \")).alias(\"word\"))\n",
    "    \n",
    "    def getRefinedData(self, rawData):\n",
    "        return (self.getRawData()\n",
    "                    .select(trim(lower(col(\"word\"))).alias(\"word\"))\n",
    "                    .where(col(\"word\") != \"\")\n",
    "                    .where(\"word rlike '[a-z]'\"))\n",
    "    \n",
    "    def getwordCount(self,refinedData):\n",
    "        return refinedData.groupBy(\"word\").count()\n",
    "\n",
    "    def overwriteWordCount(self,wordCount):\n",
    "        wordCount.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"word_count_table\")\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"Starting Word Count\")\n",
    "        rawData = self.getRawData()\n",
    "        refinedData = self.getRefinedData(rawData)\n",
    "        wordCount = self.getwordCount(refinedData)\n",
    "        self.overwriteWordCount(wordCount)\n",
    "        \n",
    "batchWordCount().run()\n",
    "spark.sql(\"select * from word_count_table\").display()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spark-streaming-word-count",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
